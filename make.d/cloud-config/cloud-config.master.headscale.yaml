#cloud-config
# Headscale Deployment Overlay
# Deploys headscale-operator and Headscale server with home LAN LoadBalancer access
# Only included for bioskop cluster

write_files:
  # Home LAN LoadBalancer IP Pool (Block 6: 192.168.1.192/27)
  - path: /var/lib/rancher/rke2/server/manifests/cilium-loadbalancer-home-lan.yaml
    content: |
      ---
      apiVersion: cilium.io/v2alpha1
      kind: CiliumLoadBalancerIPPool
      metadata:
        name: home-lan
      spec:
        blocks:
        - cidr: ${HOME_LAN_LOADBALANCER_POOL}
      ---
      apiVersion: cilium.io/v2alpha1
      kind: CiliumL2AnnouncementPolicy
      metadata:
        name: home-lan-policy
      spec:
        interfaces:
        - ^lan0$
        loadBalancerIPs: true
        nodeSelector:
          matchExpressions:
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
        serviceSelector:
          matchLabels:
            io.cilium/lb-ipam: home-lan

  # Headscale namespace
  - path: /var/lib/rancher/rke2/server/manifests/00-headscale-namespace.yaml
    content: |
      apiVersion: v1
      kind: Namespace
      metadata:
        name: headscale

  # Headscale Server with LoadBalancer
  - path: /var/lib/rancher/rke2/server/manifests/01-headscale-server.yaml
    content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: headscale-config
        namespace: headscale
      data:
        config.yaml: |
          server_url: http://192.168.1.193:8080
          listen_addr: 0.0.0.0:8080
          metrics_listen_addr: 0.0.0.0:9090
          grpc_listen_addr: 0.0.0.0:50443
          grpc_allow_insecure: true
          
          private_key_path: /var/lib/headscale/private.key
          noise:
            private_key_path: /var/lib/headscale/noise_private.key
          
          prefixes:
            v4: 100.64.0.0/10
            v6: fd7a:115c:a1e0::/48
          
          derp:
            server:
              enabled: false
            urls:
              - https://controlplane.tailscale.com/derpmap/default
            auto_update_enabled: true
            update_frequency: 24h
          
          disable_check_updates: true
          ephemeral_node_inactivity_timeout: 30m
          database:
            type: sqlite
            sqlite:
              path: /var/lib/headscale/db.sqlite
          
          policy:
            mode: file
            path: /etc/headscale/acl.json
          
          dns:
            base_domain: home.local
            nameservers:
              global:
                - 1.1.1.1
            magic_dns: true
          
          log:
            format: text
            level: info
      ---
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: headscale-acl
        namespace: headscale
      data:
        acl.json: |
          {
            "groups": {
              "group:admin": []
            },
            "tagOwners": {
              "tag:darwin": ["group:admin"],
              "tag:nixos": ["group:admin"],
              "tag:rke2": ["group:admin"]
            },
            "acls": [
              {
                "action": "accept",
                "src": ["*"],
                "dst": ["*:*"]
              }
            ],
            "ssh": [
              {
                "action": "accept",
                "src": ["group:admin", "tag:darwin", "tag:nixos"],
                "dst": ["*"],
                "users": ["autogroup:user", "root"]
              }
            ]
          }
      ---
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: headscale
        namespace: headscale
        labels:
          app: headscale
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: headscale
        template:
          metadata:
            labels:
              app: headscale
          spec:
            containers:
            - name: headscale
              image: headscale/headscale:${HEADSCALE_VERSION}
              ports:
              - name: http
                containerPort: 8080
                protocol: TCP
              - name: metrics
                containerPort: 9090
                protocol: TCP
              volumeMounts:
              - name: config
                mountPath: /etc/headscale/config.yaml
                subPath: config.yaml
              - name: acl
                mountPath: /etc/headscale/acl.json
                subPath: acl.json
              - name: data
                mountPath: /var/lib/headscale
              - name: run
                mountPath: /var/run/headscale
              command:
              - headscale
              - serve
              livenessProbe:
                httpGet:
                  path: /health
                  port: http
                initialDelaySeconds: 30
                periodSeconds: 10
              readinessProbe:
                httpGet:
                  path: /health
                  port: http
                initialDelaySeconds: 10
                periodSeconds: 5
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 512Mi
            volumes:
            - name: config
              configMap:
                name: headscale-config
            - name: acl
              configMap:
                name: headscale-acl
            - name: data
              emptyDir: {}
            - name: run
              emptyDir: {}
      ---
      apiVersion: v1
      kind: Service
      metadata:
        name: headscale
        namespace: headscale
        labels:
          app: headscale
          io.cilium/lb-ipam: home-lan
      spec:
        type: LoadBalancer
        loadBalancerIP: 192.168.1.193
        ports:
        - name: http
          port: 8080
          targetPort: 8080
          protocol: TCP
        - name: metrics
          port: 9090
          targetPort: 9090
          protocol: TCP
        selector:
          app: headscale

  # Helper Job to create initial admin user and preauth key
  - path: /var/lib/rancher/rke2/server/manifests/02-headscale-bootstrap.yaml
    content: |
      apiVersion: batch/v1
      kind: Job
      metadata:
        name: headscale-bootstrap
        namespace: headscale
      spec:
        ttlSecondsAfterFinished: 300
        template:
          spec:
            restartPolicy: OnFailure
            containers:
            - name: bootstrap
              image: headscale/headscale:${HEADSCALE_VERSION}
              command:
              - sh
              - -c
              - |
                set -e
                echo "Waiting for Headscale server to be ready..."
                until wget -q -O- http://headscale:8080/health; do
                  echo "Headscale not ready, retrying in 5s..."
                  sleep 5
                done
                
                echo "Creating admin user..."
                headscale users create admin || echo "User admin already exists"
                
                echo "Creating reusable preauth key..."
                headscale preauthkeys create --user admin --reusable --expiration 720h | \
                  tee /tmp/preauth-key.txt
                
                echo "Storing preauth key in Secret..."
                kubectl create secret generic headscale-client-auth \
                  --from-file=authkey=/tmp/preauth-key.txt \
                  --dry-run=client -o yaml | kubectl apply -f -
                
                echo "Bootstrap complete!"
              env:
              - name: HEADSCALE_CLI_ADDRESS
                value: "headscale:8080"

  # Headscale client DaemonSet - runs on all control-plane nodes
  - path: /var/lib/rancher/rke2/server/manifests/03-headscale-client-daemonset.yaml
    content: |
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: headscale-client
        namespace: headscale
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: headscale-client
      rules:
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list"]
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: headscale-client
      subjects:
      - kind: ServiceAccount
        name: headscale-client
        namespace: headscale
      roleRef:
        kind: ClusterRole
        name: headscale-client
        apiGroup: rbac.authorization.k8s.io
      ---
      apiVersion: apps/v1
      kind: DaemonSet
      metadata:
        name: headscale-client
        namespace: headscale
        labels:
          app: headscale-client
      spec:
        selector:
          matchLabels:
            app: headscale-client
        template:
          metadata:
            labels:
              app: headscale-client
          spec:
            serviceAccountName: headscale-client
            hostNetwork: true
            hostPID: true
            dnsPolicy: ClusterFirstWithHostNet
            nodeSelector:
              node-role.kubernetes.io/control-plane: "true"
            tolerations:
            - key: node-role.kubernetes.io/control-plane
              operator: Exists
              effect: NoSchedule
            initContainers:
            - name: wait-for-headscale
              image: busybox:1.36
              command:
              - sh
              - -c
              - |
                echo "Waiting for Headscale server..."
                until wget -q -O- http://headscale.headscale.svc.cluster.local:8080/health; do
                  echo "Headscale not ready, retrying in 5s..."
                  sleep 5
                done
                echo "Headscale is ready!"
            - name: wait-for-authkey
              image: busybox:1.36
              command:
              - sh
              - -c
              - |
                echo "Waiting for auth key Secret..."
                until [ -f /var/secrets/authkey ]; do
                  echo "Auth key not available, retrying in 5s..."
                  sleep 5
                done
                echo "Auth key found!"
              volumeMounts:
              - name: authkey
                mountPath: /var/secrets
            containers:
            - name: tailscale
              image: tailscale/tailscale:v1.76.6
              env:
              - name: NODE_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
              - name: TS_AUTHKEY
                valueFrom:
                  secretKeyRef:
                    name: headscale-client-auth
                    key: authkey
              - name: TS_STATE_DIR
                value: /var/lib/tailscale
              - name: TS_SOCKET
                value: /var/run/tailscale/tailscaled.sock
              - name: TS_USERSPACE
                value: "false"
              - name: TS_KUBE_SECRET
                value: ""
              command:
              - sh
              - -c
              - |
                set -e
                echo "Starting tailscaled..."
                tailscaled --state=/var/lib/tailscale/tailscaled.state --socket=/var/run/tailscale/tailscaled.sock &
                TAILSCALED_PID=$$!
                
                echo "Waiting for tailscaled socket..."
                until [ -S /var/run/tailscale/tailscaled.sock ]; do sleep 1; done
                
                echo "Connecting to Headscale..."
                tailscale up \
                  --login-server=http://headscale.headscale.svc.cluster.local:8080 \
                  --authkey=file:/var/secrets/authkey \
                  --hostname=${CLUSTER_NAME}-$$NODE_NAME \
                  --advertise-tags=tag:rke2,tag:${CLUSTER_NAME} \
                  --accept-routes \
                  --ssh \
                  --reset
                
                echo "Headscale client connected!"
                wait $$TAILSCALED_PID
              securityContext:
                privileged: true
                capabilities:
                  add:
                  - NET_ADMIN
                  - NET_RAW
              volumeMounts:
              - name: dev-net-tun
                mountPath: /dev/net/tun
              - name: tailscale-state
                mountPath: /var/lib/tailscale
              - name: tailscale-socket
                mountPath: /var/run/tailscale
              - name: authkey
                mountPath: /var/secrets
                readOnly: true
              resources:
                requests:
                  cpu: 50m
                  memory: 64Mi
                limits:
                  cpu: 200m
                  memory: 256Mi
            volumes:
            - name: dev-net-tun
              hostPath:
                path: /dev/net/tun
                type: CharDevice
            - name: tailscale-state
              hostPath:
                path: /var/lib/tailscale
                type: DirectoryOrCreate
            - name: tailscale-socket
              emptyDir: {}
            - name: authkey
              secret:
                secretName: headscale-client-auth
                items:
                - key: authkey
                  path: authkey

