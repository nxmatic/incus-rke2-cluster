# Peer1 control plane node specific configuration

name: peer1-control-node

write_files:
  # =============================================================================
  # PEER1 NODE SPECIFIC CONFIGURATION
  # =============================================================================

  # ETCD configuration for peer1 node
  - path: /etc/rancher/rke2/config.yaml.d/etcd.yaml
    content: |
      etcd-expose-metrics: true
      node-name: peer1-control-node
      with-node-id: false

  # Dedicated server fragment (templated -> rendered server.yaml)
  - path: /etc/rancher/rke2/config.yaml.d/server.yaml
    content: |
      # NOTE:
      # Port 9345 is the RKE2 supervisor (bootstrap) port used by joining server nodes.
      # The control-plane VIP (${CLUSTER_INET_VIRTUAL}) is only advertising the Kubernetes
      # API server on 6443 via the Service load balancer and does NOT forward 9345.
      # Therefore peers must talk directly to an existing server node (the initial master)
      # on its node IP for the 9345 endpoint. Keep using the VIP only for kubectl / API (6443).
      server: https://${CLUSTER_INET_MASTER}:9345

  # TODO: VIP routing - needs proper Incus network bridge configuration
  # Each node is in an isolated /24 network:  
  # - Master: 10.80.16.0/24 (contains VIP 10.80.16.240/28)
  # - Peer1:  10.80.17.0/24 (needs route to master network)
  # - Peer2:  10.80.18.0/24 (needs route to master network)
  # The routing solution depends on Incus bridge setup between networks

runcmd:
  # VIP routing configuration removed - needs proper Incus network setup
