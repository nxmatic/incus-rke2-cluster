#cloud-config
# Common cloud-init configuration for all RKE2 nodes (masters and agents)

manage_resolv_conf: true
resolv_conf:
  searchdomains:
    - mammoth-skate.ts.net

write_files:
  # Umount ZFS datasets early
  - path: /etc/systemd/system/zfs-early-umount.service
    permissions: "0644"
    content: |
      [Unit]
      Description=Early ZFS umount all datasets
      After=zfs-mount.service
      Before=basic.target
      DefaultDependencies=no

      [Service]
      Type=oneshot
      ExecStart=/usr/sbin/zfs umount -a

      [Install]
      WantedBy=basic.target

  # RKE2 server TLS SANs
  - path: /etc/rancher/rke2/config.yaml.d/tls-san.yaml
    content: |
      tls-san:
        - localhost
        - gateway
        - 127.0.0.1
        - 172.31.0.2 # kube-vip VIP address
        - 172.31.1.2 # master control node
        - 172.31.2.2 # peer1 control node
        - 172.31.3.2 # peer2 control node

  - path: /etc/rancher/rke2/config.yaml.d/etcd-metrics.yaml
    content: |
      etcd-expose-metrics: true

  # Shared kubelet config
  - path: /var/lib/rancher/rke2/agent/etc/kubelet.conf.d/01-cgroup-override.conf
    content: |
      apiVersion: kubelet.config.k8s.io/v1beta1
      kind: KubeletConfiguration
      cgroupDriver: systemd

  # Kubelet GC override
  - path: /var/lib/rancher/rke2/agent/etc/kubelet.conf.d/00-disable-gc.conf
    content: |
      apiVersion: kubelet.config.k8s.io/v1beta1
      kind: KubeletConfiguration
      kubelet-arg:
        imageGCHighThresholdPercent: 100
        imageGCLowThresholdPercent: 99

  # Shared install-pre script
  - path: /usr/local/sbin/rke2-install-pre
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail

      : Configure direnv to use flox
      direnv:config:generate() {
        mkdir -p "/root/.config/direnv/lib"
        curl -o "/root/.config/direnv/lib/flox.sh" "https://raw.githubusercontent.com/flox/flox-direnv/v1.1.0/direnv.rc"
        cat <<EoConfig | cut -c 3- > "/root/.config/direnv/direnv.toml"
        [whitelist]
        prefix= [ "/home", "/root", "/var/lib/cloud/seed/nocloud", "/var/lib/rancher/rke2", ]
      EoConfig
      }
      direnv:config:generate

      : Preload the nocloud environment
      [[ ! -d /var/lib/cloud/seed/nocloud/.flox ]] && flox init --dir=/var/lib/cloud/seed/nocloud
      flox -v -v -v install --dir=/var/lib/cloud/seed/nocloud \
        dasel \
        yq-go
      source <( flox activate --dir=/var/lib/cloud/seed/nocloud )

      : Define and load the nocloud envrc
      nocloud:envrc() {
       init:env() {
        cat /proc/1/environ |
          tr '\0' '\n' | grep -E '^(INSTALL_RKE2_TYPE|CLUSTER_|TSID|TSKEY)'
        }
        cluster:inet() {
          ip --json addr show eth0 |
            yq -p json -o shell '.[0].addr_info.[] | select(.family == "inet") | { "CLUSTER_NODE_INET": .local }'
        }
        cluster:gateway() {
          ip route show default |
            awk '/default via/ { print "CLUSTER_GATEWAY=" $3 }'
        }
        cat <<EoF
        log_status "Loading nocloud environment variables"
        set -a
        $( init:env )
        $( cluster:inet )
        $( cluster:gateway )
        set +a
        
        [[ "\$FLOX_ENV_PROJECT" != "\$PWD" ]] &&
          use flox
      EoF
      }
      nocloud:envrc > /var/lib/cloud/seed/nocloud/.envrc
      dasel -r toml -w yaml < /var/lib/cloud/seed/nocloud/.flox/env/manifest.toml | 
        yq eval '
          .profile = { "common": "source /var/lib/cloud/seed/nocloud/.flox/env/profile-common.sh" }
        ' - |
        dasel --pretty -r yaml -w toml |
        tee /tmp/manifest.toml.$$ &&
        mv /tmp/manifest.toml.$$ /var/lib/cloud/seed/nocloud/.flox/env/manifest.toml 
      cat <<'EoFloxCommonProfile' | cut -c 3- | tee /var/lib/cloud/seed/nocloud/.flox/env/profile-common.sh
        ${NOCLOUD_ENVRC:-false} ||
          source <( cd /var/lib/cloud/seed/nocloud; env HOME=${HOME:-/root} direnv exec / direnv export bash; echo 'export NOCLOUD_ENVRC=true'; )
      EoFloxCommonProfile
      source <( flox activate --dir=/var/lib/cloud/seed/nocloud )

      : Initialize the flox environment for RKE2
      [[ ! -d /var/lib/rancher/rke2/.flox ]] && flox init --dir=/var/lib/rancher/rke2
      
      flox -v -v -v install --dir=/var/lib/rancher/rke2 \
        ceph-client \
        cilium-cli \
        etcdctl \
        helmfile \
        kubernetes-helm \
        kubectl \
        yq-go # override yq-go from dependencies
        
      : Include cloud environment in RKE2 flox environment and configure groups
      dasel -r toml -w yaml < /var/lib/rancher/rke2/.flox/env/manifest.toml | 
        yq eval '
          .include = { "environments": [ { "dir": "/var/lib/cloud/seed/nocloud" } ] } |
          .install.krew = { "pkg-path": "krew", "pkg-group": "kubectl-tools" } |
          .install.kubectl-ai = { "pkg-path": "kubectl-ai", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-ktop" = { "pkg-path": "kubectl-ktop", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-neat" = { "pkg-path": "kubectl-neat", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-tree = { "pkg-path": "kubectl-tree", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-graph = { "pkg-path": "kubectl-graph", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-doctor = { "pkg-path": "kubectl-doctor", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-explore = { "pkg-path": "kubectl-explore", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-rook-ceph = { "pkg-path": "kubectl-rook-ceph", "pkg-group": "kubectl-plugins" } |
          .install.kubectl-view-secret = { "pkg-path": "kubectl-view-secret", "pkg-group": "kubectl-plugins" } |
          .install.tubekit = { "pkg-path": "tubekit", "pkg-group": "kubectl-tools" } |
          .install.yq-go = { "pkg-path": "yq-go", "pkg-group": "yaml-tools" } |
          .profile = { "common": "source /var/lib/rancher/rke2/.flox/env/profile-common.sh" }
        ' - |
        dasel --pretty -r yaml -w toml |
        tee /tmp/manifest.toml.$$ &&
        mv /tmp/manifest.toml.$$ /var/lib/rancher/rke2/.flox/env/manifest.toml 
      cat <<'EoFloxCommonProfile' | cut -c 3- | tee /var/lib/rancher/rke2/.flox/env/profile-common.sh


        : Load RKE2 environment variables
        ${RKE2_ENVRC:-false} ||
          source <( cd "/var/lib/rancher/rke2"; env HOME=${HOME:-/root} direnv exec / direnv export bash; echo 'export RKE2_ENVRC=true'; )
      EoFloxCommonProfile

      : Load the RKE2 envrc
      source <( flox activate --dir /var/lib/rancher/rke2 )

      : Initialize krew and install plugins
      mkdir -p "$KREW_ROOT"
      
      : Install krew plugins using krew directly
      krew install ctx || true
      krew install ns || true

  # Shared install script
  - path: /usr/local/sbin/rke2-install
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail

      source <( flox activate --dir /var/lib/rancher/rke2 )

      : Install the RKE2 server or agent binaries
      curl -sfL https://get.rke2.io | env DEBUG=1 sh -

      : Patch containerd to use systemd cgroup driver
      if [ -f "$CONTAINERD_CONFIG_FILE" ]; then
        sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' "$CONTAINERD_CONFIG_FILE"
      fi

      : Enable shared mount service
      systemctl daemon-reload
      systemctl enable rke2-remount-shared

  # Shared remount service
  - path: /etc/systemd/system/rke2-remount-shared.service
    content: |
      [Unit]
      Description=Remount RKE2 required volumes as shared
      Before=rke2-server.service
      DefaultDependencies=no
      [Service]
      Type=oneshot
      ExecStart=/usr/local/sbin/rke2-remount-shared
      RemainAfterExit=true
      [Install]
      WantedBy=multi-user.target

  # Shared install service
  - path: /etc/systemd/system/rke2-install.service
    content: |
      [Unit]
      Description=Run RKE2 Installation Script
      After=network.target
      ConditionPathExists=/usr/local/sbin/rke2-install
      ConditionPathExists=!/etc/systemd/system/rke2-server.service
      [Install]
      WantedBy=multi-user.target
      RequiredBy=multi-user.target
      [Service]
      Type=oneshot
      ExecStartPre=/usr/local/sbin/rke2-install-pre
      ExecStart=/usr/bin/env -S bash -c 'rke2-install && systemctl disable rke2-install.service'
      RemainAfterExit=true

  # RKE2 environment variables configuration script
  - path: /var/lib/rancher/rke2/.envrc
    permissions: "0644"
    content: |
      #!/usr/bin/env bash
      log_status "Loading RKE2 environment variables"

      set -a

      : Core RKE2 Environment Variables
      ARCH="$(dpkg --print-architecture)"
      [[ -r /etc/rancher/rke2/rke2.yaml ]] && 
        KUBECONFIG="/etc/rancher/rke2/rke2.yaml"

      : Container Runtime Configuration
      CONTAINERD_CONFIG_FILE="${PWD}/agent/etc/containerd/config.toml"
      CONTAINERD_ADDRESS="/run/k3s/containerd/containerd.sock"
      CONTAINERD_NAMESPACE="k8s.io"
      CRI_CONFIG_FILE="${PWD}/agent/etc/crictl.yaml"
      
      : etcdctl Configuration
      ETCDCTL_API="3"
      ETCDCTL_CERT="${PWD}/server/tls/etcd/server-client.crt"
      ETCDCTL_KEY="${PWD}/server/tls/etcd/server-client.key"
      ETCDCTL_CACERT="${PWD}/server/tls/etcd/server-ca.crt"
      ETCDCTL_ENDPOINTS="https://127.0.0.1:2379"
      ETCDCTL_WRITE_OUT="table"
      ETCDCTL_DIAL_TIMEOUT="10s"
      ETCDCTL_COMMAND_TIMEOUT="30s"
      
      : kubectl Configuration
      KUBECTL_OUTPUT="yaml"
      KUBECTL_EXTERNAL_DIFF="diff"
      KUBECTL_COMPLETION="true"
      
      : Helm Configuration
      HELM_DATA_HOME="${PWD}/helm"
      HELM_CONFIG_HOME="/etc/rancher/rke2/helm"
      HELM_CACHE_HOME="/var/cache/rancher/rke2/helm"
      HELM_REPOSITORY_CONFIG="/etc/rancher/rke2/helm/repositories.yaml"
      HELM_REPOSITORY_CACHE="/var/cache/rancher/rke2/helm/repository"
      HELM_PLUGINS="${PWD}/helm/plugins"
      
      : Cilium CLI Configuration
      CILIUM_CLI_MODE="kubernetes"
      CILIUM_CLI_CONTEXT="default"
      
      : Hubble Configuration
      HUBBLE_SERVER="localhost:4245"
      HUBBLE_TLS="false"

      :  Krew Configuration
      KREW_ROOT="${PWD}/krew"

      : Update PATH
      PATH="${PWD}/bin:$PATH:${KREW_ROOT}/bin"

      set +a

      [[ "$FLOX_ENV_PROJECT" != "$PWD" ]] &&
        use flox

  # root zshrc
  - path: /root/.zshrc
    permissions: "0644"
    content: |
      #!/usr/bin/env zsh

      : Define useful functions
      journalctl:unit:follow() {
        local unit="$1"
        journalctl --unit $unit --follow --no-tail |
          tee /.logs.d/${unit}.log
      }

      : Configure completions
      autoload -Uz compinit &&
        compinit
      command -v kubectl >/dev/null &&
        source <( kubectl completion zsh ) 2>/dev/null || true
      command -v helm >/dev/null &&
        source <( helm completion zsh ) 2>/dev/null || true

      : Load direnv hook
      source <( direnv hook zsh )

  # bash kube completion
  - path: /etc/bash_completion.d/kube
    permissions: "0644"
    content: |
      #!/usr/bin/env -S bash
      source <( flox activate --dir /var/lib/rancher/rke2 )

      source <( kubectl completion bash ) 2>/dev/null || true
      source <( helm completion bash ) 2>/dev/null || true

  # Shared remount script
  - path: /usr/local/sbin/rke2-remount-shared
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail
      mount --make-shared /
      mount --make-shared -t bpf bpf /sys/fs/bpf
      mount --make-shared /run

  # Shared activate script
  - path: /usr/local/sbin/rke2-activate
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail

      : Configure system-wide DNS
      ln -fs /run/systemd/resolve/resolv.conf /etc/resolv.conf
      
      : Start and wait for the RKE2 installation to complete
      systemctl enable --now rke2-install

      : Load the RKE2 environment
      source <( flox activate --dir /var/lib/rancher/rke2 )

      : Load the RKE2 environment and generate the named units
      /usr/local/sbin/rke2-enable-containerd-zfs-mount

      : Enable and launch the RKE2 service
      systemctl --no-block enable --now rke2-${INSTALL_RKE2_TYPE}

  # Script to generate the systemd mount unit for containerd zfs snapshotter
  - path: /usr/local/sbin/rke2-enable-containerd-zfs-mount
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail

      : Load the RKE2 environment
      source <( flox activate --dir /var/lib/rancher/rke2 )

      : Generate systemd mount unit for containerd zfs snapshotter
      cat <<EOF > /etc/systemd/system/var-lib-rancher-rke2-agent-containerd-io.containerd.snapshotter.v1.zfs.mount
      [Unit]
      Description=Mount containerd zfs snapshotter directory for RKE2 (ZFS dataset)
      DefaultDependencies=no
      Before=cloud-init.service
      Before=rke2-${INSTALL_RKE2_TYPE}.service

      [Mount]
      What=tank/rke2/control-nodes/${CLUSTER_NODE_NAME}/containerd
      Where=/var/lib/rancher/rke2/agent/containerd/io.containerd.snapshotter.v1.zfs
      Type=zfs
      Options=defaults

      [Install]
      WantedBy=multi-user.target
      RequiredBy=rke2-${INSTALL_RKE2_TYPE}.service
      EOF

      : Enable the mount unit
      systemctl daemon-reload
      systemctl enable var-lib-rancher-rke2-agent-containerd-io.containerd.snapshotter.v1.zfs.mount

  # Write containerd config-v3.toml.tmpl for zfs snapshotter, extending the base template
  - path: /var/lib/rancher/rke2/agent/etc/containerd/config-v3.toml.tmpl
    permissions: "0644"
    content: |
      {{ template "base" . }}

      [plugins."io.containerd.grpc.v1.cri".containerd]
        snapshotter = "zfs"

      [plugins."io.containerd.snapshotter.v1.zfs"]
        root_path = "/var/lib/rancher/rke2/agent/containerd/io.containerd.snapshotter.v1.zfs"
      
      [debug]
        level = "debug"

  - path: /etc/systemd/system/rke2-server.service.d/kubeconfig.conf
    content: |
      [Service]
      ExecStartPost=/bin/sh -xc '/usr/local/sbin/rke2-tools-configuration-directories'
      ExecStartPost=/bin/sh -xc '/usr/local/sbin/rke2-vip-kubeconfig'

  - path: /etc/systemd/system/rke2-agent.service.d/kubeconfig.conf
    content: |
      [Service]
      ExecStartPost=/bin/sh -xc '/usr/local/sbin/rke2-tools-configuration-directories'
      ExecStartPost=/bin/sh -xc '/usr/local/sbin/rke2-vip-kubeconfig'

  # Common post-start script for control plane nodes only
  - path: /etc/systemd/system/rke2-server.service.d/cilium-operator-scaling.conf
    content: |
      [Service]
      ExecStartPost=/bin/sh -xc '/usr/local/sbin/rke2-cilium-operator-scaling'

  # Dynamic Cilium operator scaling script (control plane nodes only)
  - path: /usr/local/sbin/rke2-cilium-operator-scaling
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail
      
      source <( flox activate --dir /var/lib/rancher/rke2 )
      
      : Wait for at least one node to be ready
      kubectl wait --for=condition=Ready nodes --all --timeout=300s || exit 0
      
      : Wait for Cilium DaemonSet to exist
      kubectl wait --for=jsonpath='{.metadata.name}'=cilium daemonset/cilium -n kube-system --timeout=300s || exit 0
      
      : Wait for Cilium operator deployment to exist
      kubectl wait --for=jsonpath='{.metadata.name}'=cilium-operator deployment/cilium-operator -n kube-system --timeout=300s || exit 0
      
      : Wait for Cilium DaemonSet to have at least one ready pod
      kubectl wait --for=jsonpath='{.status.numberReady}'=1 daemonset/cilium -n kube-system --timeout=300s || exit 0
      
      : Dynamic Cilium Operator Scaling
      count=$(kubectl get nodes -l node-role.kubernetes.io/control-plane --no-headers | wc -l)
      case $count in
      1)
        replicas=1;;
      2)
        replicas=2;;
      *)
        replicas=3;;
      esac

      : Scaling cilium-operator to $replicas replicas for $count control plane nodes
      kubectl scale deployment cilium-operator -n kube-system --replicas=$replicas

      : Wait for cilium-operator rollout to complete
      kubectl rollout status deployment/cilium-operator -n kube-system --timeout=60s || true

  # Create configuration tool directories
  - path: /usr/local/sbin/rke2-tools-configuration-directories
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail

      : Create directories for tool configurations
      mkdir -p /var/lib/rancher/rke2/helm/plugins
      mkdir -p /etc/rancher/rke2/helm
      mkdir -p /var/cache/rancher/rke2/helm/repository
      mkdir -p /var/lib/rancher/rke2/krew

  # Generate kubeconfig for VIP
  - path: /usr/local/sbin/rke2-vip-kubeconfig
    permissions: "0755"
    content: |
      #!/usr/bin/env -S bash -exu -o pipefail

      source <( flox activate --dir /var/lib/rancher/rke2 )

      : Create working copy of kubeconfig
      KUBECONFIG="/.kubeconfig.d/rke2-${CLUSTER_NAME}.yaml"

      mkdir -p $( dirname "$KUBECONFIG" )
      cp /etc/rancher/rke2/rke2.yaml "$KUBECONFIG"
      chmod 644 "$KUBECONFIG"

      : Apply modifications to working copy
      yq --inplace --from-file=<(cat <<EoE
      .clusters[0].cluster.name = "${CLUSTER_NAME}" |
      .clusters[0].cluster.server = "https://${CLUSTER_INET_VIRTUAL}:6443" |
      .clusters[0].name = "${CLUSTER_NAME}" |
      .contexts[0].context.cluster = "${CLUSTER_NAME}" |
      .contexts[0].context.namespace = "kube-system" |
      .contexts[0].context.user = "${CLUSTER_NAME}" |
      .contexts[0].name = "${CLUSTER_NAME}" |
      .users[0].name = "${CLUSTER_NAME}" |
      .current-context = "${CLUSTER_NAME}"
      EoE
      ) "$KUBECONFIG"

runcmd:
  - /usr/bin/env -S bash -xc 'systemctl daemon-reload'
  - /usr/bin/env -S bash -xc 'systemctl enable zfs-early-umount.service'
  - /usr/bin/env -S bash -xc 'systemctl enable rke2-install.service'
  - /usr/bin/env -S bash -xc '/usr/local/sbin/rke2-activate'
